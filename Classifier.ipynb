{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc86e478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ yt-dlp already installed\n",
      "‚úÖ librosa already installed\n",
      "‚úÖ soundfile already installed\n",
      "üì¶ Installing openai-whisper...\n",
      "‚úÖ transformers already installed\n",
      "‚úÖ torch already installed\n",
      "‚úÖ numpy already installed\n",
      "‚úÖ pandas already installed\n",
      "‚úÖ requests already installed\n",
      "‚úÖ pydub already installed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 1: Install Required Packages\n",
    "import os\n",
    "def install_requirements():\n",
    "    \"\"\"Install all required packages\"\"\"\n",
    "    packages = [\n",
    "        \"yt-dlp\",\n",
    "        \"librosa\",\n",
    "        \"soundfile\", \n",
    "        \"openai-whisper\",\n",
    "        \"transformers\",\n",
    "        \"torch\",\n",
    "        \"numpy\",\n",
    "        \"pandas\",\n",
    "        \"requests\",\n",
    "        \"pydub\"\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            __import__(package.replace('-', '_'))\n",
    "            print(f\"‚úÖ {package} already installed\")\n",
    "        except ImportError:\n",
    "            print(f\"üì¶ Installing {package}...\")\n",
    "            os.system(f\"pip install {package}\")\n",
    "\n",
    "# Uncomment the next line if you need to install packages\n",
    "install_requirements()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e1ffa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ English Accent Detection System\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yt_dlp as ytdlp\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "\n",
    "# ML and Audio Processing\n",
    "import whisper\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Utilities\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üéØ English Accent Detection System\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7608ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 2: Audio Extraction Module\n",
    "\n",
    "class AudioExtractor:\n",
    "    \"\"\"Handle video URL processing and audio extraction\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.temp_dir = tempfile.mkdtemp()\n",
    "        self.supported_formats = ['mp4', 'mp3', 'wav', 'avi', 'mov', 'webm']\n",
    "        \n",
    "    def is_valid_url(self, url):\n",
    "        \"\"\"Validate if URL is properly formatted\"\"\"\n",
    "        try:\n",
    "            result = urlparse(url)\n",
    "            return all([result.scheme, result.netloc])\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def detect_url_type(self, url):\n",
    "        \"\"\"Detect the type of URL (direct file, YouTube, Loom, etc.)\"\"\"\n",
    "        url_lower = url.lower()\n",
    "        \n",
    "        if 'youtube.com' in url_lower or 'youtu.be' in url_lower:\n",
    "            return 'youtube'\n",
    "        elif 'loom.com' in url_lower:\n",
    "            return 'loom'\n",
    "        elif any(ext in url_lower for ext in self.supported_formats):\n",
    "            return 'direct'\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    \n",
    "    def download_audio(self, url):\n",
    "        \"\"\"Download and extract audio from URL\"\"\"\n",
    "        print(f\"üîÑ Processing URL: {url[:50]}...\")\n",
    "        \n",
    "        if not self.is_valid_url(url):\n",
    "            raise ValueError(\"Invalid URL format\")\n",
    "        \n",
    "        url_type = self.detect_url_type(url)\n",
    "        audio_path = None\n",
    "        \n",
    "        try:\n",
    "            if url_type in ['youtube', 'loom', 'unknown']:\n",
    "                # Use yt-dlp for video platforms\n",
    "                audio_path = self._extract_with_ytdlp(url)\n",
    "            elif url_type == 'direct':\n",
    "                # Direct download for MP4/MP3 files\n",
    "                audio_path = self._download_direct(url)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported URL type: {url_type}\")\n",
    "                \n",
    "            print(f\"‚úÖ Audio extracted successfully\")\n",
    "            return audio_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error extracting audio: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _extract_with_ytdlp(self, url):\n",
    "        \"\"\"Extract audio using yt-dlp\"\"\"\n",
    "        import yt_dlp\n",
    "        \n",
    "        output_path = os.path.join(self.temp_dir, 'extracted_audio.wav')\n",
    "        \n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'outtmpl': os.path.join(self.temp_dir, 'temp_video.%(ext)s'),\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'wav',\n",
    "                'preferredquality': '192',\n",
    "            }],\n",
    "            'postprocessor_args': ['-ar', '16000'],  # 16kHz for speech recognition\n",
    "        }\n",
    "        \n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "        \n",
    "        # Find the extracted audio file\n",
    "        for file in os.listdir(self.temp_dir):\n",
    "            if file.endswith('.wav'):\n",
    "                return os.path.join(self.temp_dir, file)\n",
    "        \n",
    "        raise Exception(\"Audio extraction failed\")\n",
    "    \n",
    "    def _download_direct(self, url):\n",
    "        \"\"\"Download direct audio/video files\"\"\"\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Determine file extension\n",
    "        content_type = response.headers.get('content-type', '')\n",
    "        if 'audio' in content_type:\n",
    "            ext = '.mp3'\n",
    "        elif 'video' in content_type:\n",
    "            ext = '.mp4'\n",
    "        else:\n",
    "            ext = '.mp4'  # default\n",
    "        \n",
    "        temp_file = os.path.join(self.temp_dir, f'downloaded{ext}')\n",
    "        \n",
    "        with open(temp_file, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        # Convert to WAV if needed\n",
    "        if ext != '.wav':\n",
    "            return self._convert_to_wav(temp_file)\n",
    "        return temp_file\n",
    "    \n",
    "    def _convert_to_wav(self, input_path):\n",
    "        \"\"\"Convert audio file to WAV format\"\"\"\n",
    "        from pydub import AudioSegment\n",
    "        \n",
    "        audio = AudioSegment.from_file(input_path)\n",
    "        wav_path = os.path.join(self.temp_dir, 'converted.wav')\n",
    "        audio.export(wav_path, format='wav', parameters=['-ar', '16000'])\n",
    "        return wav_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9d5b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Speech Analysis Engine\n",
    "\n",
    "\n",
    "class SpeechAnalyzer:\n",
    "    \"\"\"Analyze speech patterns for accent detection\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.whisper_model = None\n",
    "        self.load_models()\n",
    "        \n",
    "        # Accent-specific phonetic patterns\n",
    "        self.accent_patterns = {\n",
    "            'american': {\n",
    "                'r_colored': True,\n",
    "                'vowel_patterns': ['√¶', '…ë', '…î'],\n",
    "                'keywords': ['schedule', 'tomato', 'dance'],\n",
    "                'rhotic': True\n",
    "            },\n",
    "            'british': {\n",
    "                'r_colored': False,\n",
    "                'vowel_patterns': ['…ëÀê', '…í', '…úÀê'],\n",
    "                'keywords': ['schedule', 'tomato', 'dance'],\n",
    "                'rhotic': False\n",
    "            },\n",
    "            'australian': {\n",
    "                'r_colored': False,\n",
    "                'vowel_patterns': ['√¶…™', '…ô â', 'o…™'],\n",
    "                'keywords': ['today', 'mate', 'about'],\n",
    "                'rhotic': False\n",
    "            },\n",
    "            'canadian': {\n",
    "                'r_colored': True,\n",
    "                'vowel_patterns': ['a ä', 'a…™'],\n",
    "                'keywords': ['about', 'house', 'out'],\n",
    "                'canadian_raising': True\n",
    "            },\n",
    "            'irish': {\n",
    "                'r_colored': True,\n",
    "                'vowel_patterns': ['…™…ô', 'e…™', 'o ä'],\n",
    "                'keywords': ['three', 'thirty', 'girl'],\n",
    "                'rhotic': True\n",
    "            },\n",
    "            'south_african': {\n",
    "                'r_colored': False,\n",
    "                'vowel_patterns': ['…™…ô', 'e…ô', ' ä…ô'],\n",
    "                'keywords': ['here', 'there', 'sure'],\n",
    "                'kit_split': True\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def load_models(self):\n",
    "        \"\"\"Load speech recognition models\"\"\"\n",
    "        print(\"ü§ñ Loading speech analysis models...\")\n",
    "        try:\n",
    "            # Load Whisper for transcription\n",
    "            self.whisper_model = whisper.load_model(\"base\")\n",
    "            print(\"‚úÖ Whisper model loaded\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error loading models: {e}\")\n",
    "    \n",
    "    def transcribe_audio(self, audio_path):\n",
    "        \"\"\"Transcribe audio to text with phonetic information\"\"\"\n",
    "        print(\"üé§ Transcribing audio...\")\n",
    "        \n",
    "        try:\n",
    "            # Transcribe with Whisper\n",
    "            result = self.whisper_model.transcribe(audio_path)\n",
    "            text = result['text']\n",
    "            \n",
    "            # Extract additional features\n",
    "            audio_features = self._extract_audio_features(audio_path)\n",
    "            \n",
    "            return {\n",
    "                'text': text,\n",
    "                'segments': result.get('segments', []),\n",
    "                'audio_features': audio_features\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Transcription error: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _extract_audio_features(self, audio_path):\n",
    "        \"\"\"Extract acoustic features for accent analysis\"\"\"\n",
    "        try:\n",
    "            # Load audio\n",
    "            y, sr = librosa.load(audio_path, sr=16000)\n",
    "            \n",
    "            # Extract features\n",
    "            features = {\n",
    "                'mfcc': librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).mean(axis=1),\n",
    "                'spectral_centroid': librosa.feature.spectral_centroid(y=y, sr=sr).mean(),\n",
    "                'zero_crossing_rate': librosa.feature.zero_crossing_rate(y).mean(),\n",
    "                'tempo': librosa.beat.tempo(y=y, sr=sr)[0] if len(librosa.beat.tempo(y=y, sr=sr)) > 0 else 120,\n",
    "                'pitch_range': self._get_pitch_range(y, sr),\n",
    "                'formants': self._estimate_formants(y, sr)\n",
    "            }\n",
    "            \n",
    "            return features\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Feature extraction warning: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def _get_pitch_range(self, y, sr):\n",
    "        \"\"\"Calculate pitch range\"\"\"\n",
    "        try:\n",
    "            pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "            pitches = pitches[magnitudes > np.median(magnitudes)]\n",
    "            pitches = pitches[pitches > 0]\n",
    "            \n",
    "            if len(pitches) > 0:\n",
    "                return {'min': float(np.min(pitches)), 'max': float(np.max(pitches))}\n",
    "            return {'min': 0, 'max': 0}\n",
    "        except:\n",
    "            return {'min': 0, 'max': 0}\n",
    "    \n",
    "    def _estimate_formants(self, y, sr):\n",
    "        \"\"\"Estimate formant frequencies\"\"\"\n",
    "        try:\n",
    "            # Simple formant estimation using spectral peaks\n",
    "            fft = np.fft.fft(y)\n",
    "            freqs = np.fft.fftfreq(len(fft), 1/sr)\n",
    "            magnitude = np.abs(fft)\n",
    "            \n",
    "            # Find peaks (simplified)\n",
    "            peaks = []\n",
    "            for i in range(1, len(magnitude)-1):\n",
    "                if magnitude[i] > magnitude[i-1] and magnitude[i] > magnitude[i+1]:\n",
    "                    if freqs[i] > 0 and freqs[i] < 4000:  # Focus on speech range\n",
    "                        peaks.append(freqs[i])\n",
    "            \n",
    "            peaks.sort()\n",
    "            return peaks[:3] if len(peaks) >= 3 else peaks\n",
    "        except:\n",
    "            return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44f512a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Accent Classification Engine\n",
    "\n",
    "class AccentClassifier:\n",
    "    \"\"\"Classify English accents based on speech analysis\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.accent_features = {\n",
    "            'american': {\n",
    "                'rhotic': 1.0,\n",
    "                'vowel_shift': 0.8,\n",
    "                'intonation': 'flat',\n",
    "                'tempo': 'medium',\n",
    "                'key_words': {\n",
    "                    'dance': 'd√¶ns',\n",
    "                    'bath': 'b√¶Œ∏',\n",
    "                    'car': 'k…ër',\n",
    "                    'park': 'p…ërk'\n",
    "                }\n",
    "            },\n",
    "            'british': {\n",
    "                'rhotic': 0.0,\n",
    "                'vowel_shift': 0.3,\n",
    "                'intonation': 'rising',\n",
    "                'tempo': 'medium',\n",
    "                'key_words': {\n",
    "                    'dance': 'd…ëÀêns',\n",
    "                    'bath': 'b…ëÀêŒ∏',\n",
    "                    'car': 'k…ëÀê',\n",
    "                    'park': 'p…ëÀêk'\n",
    "                }\n",
    "            },\n",
    "            'australian': {\n",
    "                'rhotic': 0.0,\n",
    "                'vowel_shift': 0.9,\n",
    "                'intonation': 'rising',\n",
    "                'tempo': 'fast',\n",
    "                'key_words': {\n",
    "                    'today': 't…ôÀàd√¶…™',\n",
    "                    'mate': 'm√¶…™t',\n",
    "                    'about': '…ôÀàb√¶…™t'\n",
    "                }\n",
    "            },\n",
    "            'canadian': {\n",
    "                'rhotic': 0.8,\n",
    "                'vowel_shift': 0.6,\n",
    "                'intonation': 'rising',\n",
    "                'tempo': 'medium',\n",
    "                'canadian_raising': True,\n",
    "                'key_words': {\n",
    "                    'about': '…ôÀàb å ät',\n",
    "                    'house': 'h å äs',\n",
    "                    'out': ' å ät'\n",
    "                }\n",
    "            },\n",
    "            'irish': {\n",
    "                'rhotic': 0.7,\n",
    "                'vowel_shift': 0.4,\n",
    "                'intonation': 'musical',\n",
    "                'tempo': 'variable',\n",
    "                'key_words': {\n",
    "                    'three': 'triÀê',\n",
    "                    'thirty': 't…úrti',\n",
    "                    'girl': 'g…úrl'\n",
    "                }\n",
    "            },\n",
    "            'south_african': {\n",
    "                'rhotic': 0.2,\n",
    "                'vowel_shift': 0.7,\n",
    "                'intonation': 'flat',\n",
    "                'tempo': 'medium',\n",
    "                'key_words': {\n",
    "                    'here': 'hi…ôr',\n",
    "                    'there': '√∞e…ôr',\n",
    "                    'sure': ' Éu…ôr'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def classify_accent(self, transcription_data):\n",
    "        \"\"\"Main accent classification function\"\"\"\n",
    "        print(\"üéØ Classifying accent...\")\n",
    "        \n",
    "        text = transcription_data['text']\n",
    "        audio_features = transcription_data.get('audio_features', {})\n",
    "        \n",
    "        # Calculate scores for each accent\n",
    "        accent_scores = {}\n",
    "        \n",
    "        for accent_name, accent_features in self.accent_features.items():\n",
    "            score = self._calculate_accent_score(text, audio_features, accent_features)\n",
    "            accent_scores[accent_name] = score\n",
    "        \n",
    "        # Find best match\n",
    "        best_accent = max(accent_scores, key=accent_scores.get)\n",
    "        confidence = accent_scores[best_accent]\n",
    "        \n",
    "        # Normalize confidence to 0-100%\n",
    "        confidence_percentage = min(100, max(0, confidence * 100))\n",
    "        \n",
    "        result = {\n",
    "            'accent': best_accent,\n",
    "            'confidence': confidence_percentage,\n",
    "            'scores': accent_scores,\n",
    "            'explanation': self._generate_explanation(best_accent, confidence_percentage, text)\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ Classification complete: {best_accent.title()} ({confidence_percentage:.1f}%)\")\n",
    "        return result\n",
    "    \n",
    "    def _calculate_accent_score(self, text, audio_features, accent_features):\n",
    "        \"\"\"Calculate similarity score between speech and accent pattern\"\"\"\n",
    "        score = 0.0\n",
    "        weight_sum = 0.0\n",
    "        \n",
    "        # Text-based analysis\n",
    "        text_score = self._analyze_text_patterns(text, accent_features)\n",
    "        score += text_score * 0.4\n",
    "        weight_sum += 0.4\n",
    "        \n",
    "        # Audio feature analysis\n",
    "        if audio_features:\n",
    "            audio_score = self._analyze_audio_patterns(audio_features, accent_features)\n",
    "            score += audio_score * 0.6\n",
    "            weight_sum += 0.6\n",
    "        \n",
    "        return score / weight_sum if weight_sum > 0 else 0.0\n",
    "    \n",
    "    def _analyze_text_patterns(self, text, accent_features):\n",
    "        \"\"\"Analyze text for accent-specific patterns\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # Convert to lowercase for analysis\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Check for key words\n",
    "        key_words = accent_features.get('key_words', {})\n",
    "        found_keywords = 0\n",
    "        for word in key_words:\n",
    "            if word in text_lower:\n",
    "                found_keywords += 1\n",
    "        \n",
    "        if key_words:\n",
    "            score += (found_keywords / len(key_words)) * 0.5\n",
    "        \n",
    "        # Check for rhotic features (presence of 'r' sounds)\n",
    "        rhotic_expected = accent_features.get('rhotic', 0.5)\n",
    "        r_count = text_lower.count('r')\n",
    "        total_chars = len(text_lower.replace(' ', ''))\n",
    "        r_ratio = r_count / total_chars if total_chars > 0 else 0\n",
    "        \n",
    "        # Score based on expected rhoticity\n",
    "        if rhotic_expected > 0.5:\n",
    "            score += min(r_ratio * 2, 0.3)  # Reward rhotic accents\n",
    "        else:\n",
    "            score += max(0.3 - r_ratio * 2, 0)  # Reward non-rhotic accents\n",
    "        \n",
    "        # Length and complexity (some accents are more verbose)\n",
    "        word_count = len(text.split())\n",
    "        if word_count > 10:  # Minimum for reliable analysis\n",
    "            score += 0.2\n",
    "        \n",
    "        return min(score, 1.0)\n",
    "    \n",
    "    def _analyze_audio_patterns(self, audio_features, accent_features):\n",
    "        \"\"\"Analyze audio features for accent classification\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # Tempo analysis\n",
    "        tempo = audio_features.get('tempo', 120)\n",
    "        expected_tempo = accent_features.get('tempo', 'medium')\n",
    "        \n",
    "        if expected_tempo == 'fast' and tempo > 130:\n",
    "            score += 0.2\n",
    "        elif expected_tempo == 'medium' and 110 <= tempo <= 130:\n",
    "            score += 0.2\n",
    "        elif expected_tempo == 'slow' and tempo < 110:\n",
    "            score += 0.2\n",
    "        \n",
    "        # Pitch range analysis\n",
    "        pitch_range = audio_features.get('pitch_range', {})\n",
    "        if pitch_range:\n",
    "            pitch_variance = pitch_range.get('max', 0) - pitch_range.get('min', 0)\n",
    "            intonation = accent_features.get('intonation', 'flat')\n",
    "            \n",
    "            if intonation == 'rising' and pitch_variance > 100:\n",
    "                score += 0.2\n",
    "            elif intonation == 'flat' and pitch_variance < 100:\n",
    "                score += 0.2\n",
    "            elif intonation == 'musical' and pitch_variance > 150:\n",
    "                score += 0.3\n",
    "        \n",
    "        # MFCC-based analysis (simplified)\n",
    "        mfcc = audio_features.get('mfcc', [])\n",
    "        if len(mfcc) >= 13:\n",
    "            # Compare with typical patterns (this is simplified)\n",
    "            vowel_shift = accent_features.get('vowel_shift', 0.5)\n",
    "            mfcc_variance = np.var(mfcc)\n",
    "            \n",
    "            if vowel_shift > 0.7 and mfcc_variance > 0.5:\n",
    "                score += 0.3\n",
    "            elif vowel_shift < 0.4 and mfcc_variance < 0.3:\n",
    "                score += 0.3\n",
    "        \n",
    "        return min(score, 1.0)\n",
    "    \n",
    "    def _generate_explanation(self, accent, confidence, text):\n",
    "        \"\"\"Generate explanation for the classification\"\"\"\n",
    "        explanations = {\n",
    "            'american': f\"Detected American English features including rhotic 'r' sounds and typical vowel patterns. Confidence: {confidence:.1f}%\",\n",
    "            'british': f\"Identified British English characteristics such as non-rhotic pronunciation and distinct vowel sounds. Confidence: {confidence:.1f}%\",\n",
    "            'australian': f\"Found Australian English markers including vowel shifts and distinctive intonation patterns. Confidence: {confidence:.1f}%\",\n",
    "            'canadian': f\"Detected Canadian English features including potential Canadian raising and rhotic patterns. Confidence: {confidence:.1f}%\",\n",
    "            'irish': f\"Identified Irish English characteristics including musical intonation and specific vowel patterns. Confidence: {confidence:.1f}%\",\n",
    "            'south_african': f\"Found South African English markers including specific vowel changes and intonation. Confidence: {confidence:.1f}%\"\n",
    "        }\n",
    "        \n",
    "        base_explanation = explanations.get(accent, f\"Classified as {accent} accent with {confidence:.1f}% confidence\")\n",
    "        \n",
    "        # Add context about text length\n",
    "        word_count = len(text.split())\n",
    "        if word_count < 10:\n",
    "            base_explanation += \" (Note: Short audio sample may limit accuracy)\"\n",
    "        elif word_count > 50:\n",
    "            base_explanation += \" (Good sample length for reliable analysis)\"\n",
    "        \n",
    "        return base_explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c51c535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 5: Main Processing Pipeline\n",
    "\n",
    "class AccentDetectionSystem:\n",
    "    \"\"\"Complete accent detection system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.audio_extractor = AudioExtractor()\n",
    "        self.speech_analyzer = SpeechAnalyzer()\n",
    "        self.accent_classifier = AccentClassifier()\n",
    "        \n",
    "    def process_video_url(self, url):\n",
    "        \"\"\"Main processing pipeline\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"üé¨ ENGLISH ACCENT DETECTION SYSTEM\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Extract audio\n",
    "            print(\"\\n1Ô∏è‚É£ AUDIO EXTRACTION\")\n",
    "            audio_path = self.audio_extractor.download_audio(url)\n",
    "            \n",
    "            # Step 2: Analyze speech\n",
    "            print(\"\\n2Ô∏è‚É£ SPEECH ANALYSIS\")\n",
    "            transcription_data = self.speech_analyzer.transcribe_audio(audio_path)\n",
    "            \n",
    "            # Step 3: Classify accent\n",
    "            print(\"\\n3Ô∏è‚É£ ACCENT CLASSIFICATION\")\n",
    "            classification_result = self.accent_classifier.classify_accent(transcription_data)\n",
    "            \n",
    "            # Step 4: Compile results\n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            final_result = {\n",
    "                'url': url,\n",
    "                'transcript': transcription_data['text'],\n",
    "                'accent': classification_result['accent'],\n",
    "                'confidence': classification_result['confidence'],\n",
    "                'explanation': classification_result['explanation'],\n",
    "                'all_scores': classification_result['scores'],\n",
    "                'processing_time': round(processing_time, 2),\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            # Display results\n",
    "            self._display_results(final_result)\n",
    "            \n",
    "            return final_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_result = {\n",
    "                'error': str(e),\n",
    "                'url': url,\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            print(f\"\\n‚ùå ERROR: {str(e)}\")\n",
    "            return error_result\n",
    "    \n",
    "    def _display_results(self, result):\n",
    "        \"\"\"Display formatted results\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"üìä RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        print(f\"üéØ Detected Accent: {result['accent'].title()}\")\n",
    "        print(f\"üìà Confidence Score: {result['confidence']:.1f}%\")\n",
    "        print(f\"‚è±Ô∏è Processing Time: {result['processing_time']}s\")\n",
    "        \n",
    "        print(f\"\\nüìù Transcript Preview:\")\n",
    "        transcript = result['transcript'][:200] + \"...\" if len(result['transcript']) > 200 else result['transcript']\n",
    "        print(f\"   {transcript}\")\n",
    "        \n",
    "        print(f\"\\nüí° Explanation:\")\n",
    "        print(f\"   {result['explanation']}\")\n",
    "        \n",
    "        print(f\"\\nüìä All Accent Scores:\")\n",
    "        for accent, score in result['all_scores'].items():\n",
    "            bar = \"‚ñà\" * int(score * 20) + \"‚ñë\" * (20 - int(score * 20))\n",
    "            print(f\"   {accent.title():12} [{bar}] {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a3195eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 6: Testing and Examples\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"Run system tests with sample URLs\"\"\"\n",
    "    system = AccentDetectionSystem()\n",
    "    \n",
    "    # Test URLs (you'll need to replace these with actual working URLs)\n",
    "    test_urls = [\n",
    "        # Add your test URLs here\n",
    "        \"https://sample-videos.com/zip/10/mp4/SampleVideo_1280x720_1mb.mp4\",  # Replace with actual\n",
    "    ]\n",
    "    \n",
    "    print(\"üß™ Running system tests...\")\n",
    "    \n",
    "    for i, url in enumerate(test_urls, 1):\n",
    "        print(f\"\\n{'='*20} TEST {i} {'='*20}\")\n",
    "        try:\n",
    "            result = system.process_video_url(url)\n",
    "            print(\"‚úÖ Test passed\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Test failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c7d7eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 7: Interactive Usage\n",
    "def interactive_mode():\n",
    "    \"\"\"Interactive mode for testing\"\"\"\n",
    "    system = AccentDetectionSystem()\n",
    "    \n",
    "    print(\"\\nüé§ Welcome to the English Accent Detection System!\")\n",
    "    print(\"Enter video URLs to analyze accents (or 'quit' to exit)\")\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\n\" + \"-\"*50)\n",
    "        url = input(\"Enter video URL: \").strip()\n",
    "        \n",
    "        if url.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"üëã Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if not url:\n",
    "            print(\"Please enter a valid URL\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            result = system.process_video_url(url)\n",
    "            \n",
    "            # Save result to file\n",
    "            with open(f'accent_result_{int(time.time())}.json', 'w') as f:\n",
    "                json.dump(result, f, indent=2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing URL: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "336d1fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INITIALIZING ACCENT DETECTION SYSTEM\n",
      "============================================================\n",
      "ü§ñ Loading speech analysis models...\n",
      "‚úÖ Whisper model loaded\n",
      "‚úÖ System initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 8: Execute the System\n",
    "\n",
    "print(\"üöÄ INITIALIZING ACCENT DETECTION SYSTEM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize the system\n",
    "try:\n",
    "    system = AccentDetectionSystem()\n",
    "    print(\"‚úÖ System initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå System initialization failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33467dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 9: Quick Test Function\n",
    "\n",
    "def quick_test(url):\n",
    "    \"\"\"Quick test function for immediate results\"\"\"\n",
    "    print(f\"\\nüéØ QUICK TEST\")\n",
    "    print(f\"URL: {url}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        system = AccentDetectionSystem()\n",
    "        result = system.process_video_url(url)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f80d5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üí° EXAMPLE USAGE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# STEP 10: Example Usage\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí° EXAMPLE USAGE\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11727a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nüß™ Running sample test...\n",
      "Note: Replace the sample_url with a real video URL containing English speech\n",
      "\n",
      "üéØ QUICK TEST\n",
      "URL: https://www.youtube.com/watch?v=0Okxsszt624\n",
      "--------------------------------------------------\n",
      "ü§ñ Loading speech analysis models...\n",
      "‚úÖ Whisper model loaded\n",
      "\n",
      "==================================================\n",
      "üé¨ ENGLISH ACCENT DETECTION SYSTEM\n",
      "==================================================\n",
      "\n",
      "1Ô∏è‚É£ AUDIO EXTRACTION\n",
      "üîÑ Processing URL: https://www.youtube.com/watch?v=0Okxsszt624...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=0Okxsszt624\n",
      "[youtube] 0Okxsszt624: Downloading webpage\n",
      "[youtube] 0Okxsszt624: Downloading tv client config\n",
      "[youtube] 0Okxsszt624: Downloading tv player API JSON\n",
      "[youtube] 0Okxsszt624: Downloading ios player API JSON\n",
      "[youtube] 0Okxsszt624: Downloading m3u8 information\n",
      "[info] 0Okxsszt624: Downloading 1 format(s): 251\n",
      "[download] Destination: C:\\Users\\SAHIL~1.RAN\\AppData\\Local\\Temp\\tmpvubdgvkf\\temp_video.webm\n",
      "[download] 100% of   13.79MiB in 00:00:01 at 8.67MiB/s   \n",
      "[ExtractAudio] Destination: C:\\Users\\SAHIL~1.RAN\\AppData\\Local\\Temp\\tmpvubdgvkf\\temp_video.wav\n",
      "Deleting original file C:\\Users\\SAHIL~1.RAN\\AppData\\Local\\Temp\\tmpvubdgvkf\\temp_video.webm (pass -k to keep)\n",
      "‚úÖ Audio extracted successfully\n",
      "\n",
      "2Ô∏è‚É£ SPEECH ANALYSIS\n",
      "üé§ Transcribing audio...\n",
      "\n",
      "3Ô∏è‚É£ ACCENT CLASSIFICATION\n",
      "üéØ Classifying accent...\n",
      "‚úÖ Classification complete: Australian (71.1%)\n",
      "\n",
      "==================================================\n",
      "üìä RESULTS\n",
      "==================================================\n",
      "üéØ Detected Accent: Australian\n",
      "üìà Confidence Score: 71.1%\n",
      "‚è±Ô∏è Processing Time: 101.72s\n",
      "\n",
      "üìù Transcript Preview:\n",
      "    EnglishLeap podcast. From Speak English with Class. Hey everyone, welcome back to the EnglishLeap podcast. You're go to English podcast for learning English and improving your life. I'm Aaron and as ...\n",
      "\n",
      "üí° Explanation:\n",
      "   Found Australian English markers including vowel shifts and distinctive intonation patterns. Confidence: 71.1% (Good sample length for reliable analysis)\n",
      "\n",
      "üìä All Accent Scores:\n",
      "   American     [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0.353\n",
      "   British      [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0.327\n",
      "   Australian   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0.711\n",
      "   Canadian     [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0.376\n",
      "   Irish        [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0.369\n",
      "   South_African [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0.357\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 11: Sample Test\n",
    "\n",
    "sample_url = \"https://www.youtube.com/watch?v=0Okxsszt624\"  # Replace this!\n",
    "\n",
    "print(\"\\\\nüß™ Running sample test...\")\n",
    "print(\"Note: Replace the sample_url with a real video URL containing English speech\")\n",
    "result = quick_test(sample_url)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
